# Nano GPT-3

## Paper

[2020 GPT-3: Language Models are Few-Shot Learners](https://arxiv.org/pdf/2005.14165.pdf)

![](image/gpt3.png)

- Major innovations
    - Alternating dense and locally banded sparse attention patterns in the layers of the transformer, similar to the Sparse Transformer
    - Few-shot prompting
    - Bigger
- Existing innovations used
    - Transformer

## Codes

TODO: write the demo codes